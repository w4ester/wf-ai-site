---
title: "Beyond Engagement: Building Technology for Youth Flourishing"
tags: guardian, philosophy, research, youth, flourishing, self-determination, ai, ethics
date: 2026-01-12
---

# Beyond Engagement: Building Technology for Youth Flourishing

*What if we designed technology to help young people flourish, not just to capture their attention?*

---

## The Fundamental Problem

The technology our children use every day was designed with one primary goal: **maximize engagement**.

Not learning. Not growth. Not wellbeing. Engagement.

Every feature, every notification, every infinite scroll was optimized by thousands of engineers to capture and hold attention. The business model is simple: attention is sold to advertisers. More attention = more revenue.

But research from [Georgetown Law](https://www.law.georgetown.edu/denny-center/blog/the-attention-economy/) reveals the true cost:

> "What appears as 'choice' in digital interfaces is often a carefully designed illusion reinforcing compulsive engagement rather than supporting autonomous decision-making. Declining cognitive autonomy poses a significant threat to psychological resilience, democratic deliberation, and the normative goals of liberal education."

Young people are paying for the attention economy with their autonomy, their development, and their mental health.

---

## The Research is Clear

### The Anxious Generation

Jonathan Haidt's [*The Anxious Generation*](https://jonathanhaidt.com/anxious-generation/) documents how the "play-based childhood" was "finally wiped out by the arrival of the phone-based childhood in the early 2010s." His research identifies over a dozen mechanisms causing harm:

- Sleep deprivation
- Attention fragmentation
- Addiction
- Loneliness
- Social contagion
- Social comparison
- Perfectionism

His core insight: **"Overprotection in the real world and underprotection in the virtual world"** created the anxious generation.

### Self-Determination Theory

[Decades of research](https://selfdeterminationtheory.org/theory/) by Deci and Ryan shows that human flourishing requires three fundamental psychological needs:

1. **Autonomy** — The feeling of being the author of your own actions
2. **Competence** — The feeling of mastery and effectiveness
3. **Relatedness** — The feeling of meaningful connection with others

When technology supports these needs, people thrive. When technology undermines them, people suffer.

The problem? Most apps are designed to *undermine* autonomy (through manipulation), create *false competence* (through achievement badges for non-meaningful tasks), and provide *shallow relatedness* (through likes and followers instead of genuine connection).

### Hedonic vs Eudaimonic Wellbeing

Research distinguishes between two types of wellbeing:

**Hedonic wellbeing** — Pleasure, fun, feeling good in the moment

**Eudaimonic wellbeing** — Meaning, purpose, self-realization, living up to one's potential

[Studies show](https://www.researchsquare.com/article/rs-7755268/v1) that young children are more driven by hedonic motives, while eudaimonic motives increase with age. The problem: most apps optimize purely for hedonic experience — immediate pleasure, dopamine hits, endless entertainment.

But [research confirms](https://pmc.ncbi.nlm.nih.gov/articles/PMC5985470/) that "factors such as engagement and enjoyment do not necessarily contribute to sustainable wellbeing. Indeed, studies in video games and media consumption confirm that too much engagement can crowd-out healthy activities to the detriment of overall wellbeing."

The question researchers are now asking: **"How can technology be designed to support wellbeing that encompasses more than just immediate hedonic experience, but also its longer-term eudaimonia, or true flourishing?"**

---

## What Different Incentives Look Like

### The METUX Framework

The [METUX model](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2018.00797/full) (Motivation, Engagement and Thriving in User Experience) provides a framework for designing technology that supports psychological needs across multiple "spheres" of impact:

```
METUX SPHERES:

Interface → Task → Behavior → Life
────────────────────────────────────────────
Short-term   →    →    →    Long-term impact

A social media app might satisfy needs AT THE INTERFACE
(fun, engaging, feels competent) while UNDERMINING needs
AT THE LIFE LEVEL (addiction, social comparison, anxiety)
```

The insight: **engagement at one level can cause harm at another**. A game that's deeply engaging in the moment might crowd out sleep, relationships, and real-world competence development.

### The Four Pillars of Flourishing

Harvard's [Human Flourishing Program](https://hfh.fas.harvard.edu/global-flourishing-study) research identifies four pillars that exhibit plasticity — meaning they can be developed:

1. **Awareness** — Knowing one's own mind
2. **Connection** — Meaningful relationships
3. **Insight** — Understanding how one's mind works
4. **Purpose** — Having something larger than oneself

Technology designed for these pillars looks fundamentally different than technology designed for engagement.

### Developmentally Aligned Design

[Recent research](https://link.springer.com/article/10.1007/s44436-025-00009-z) proposes "Developmentally Aligned Design" (DAD) for building AI systems that meet children where they are — cognitively, socially, and emotionally.

The four principles:
1. **Perceptual fit** — Matching children's perceptual capabilities
2. **Cognitive scaffolding** — Using Zone-of-Proximal-Development progressions
3. **Interface simplicity** — Appropriate complexity
4. **Relational integrity** — Respecting the child as a developing person

This is a paradigm shift: **design WITH child development in mind, not against it**.

---

## The Alternative Architecture

### What Guardian Is Building

Guardian Protocol isn't just another parental control app. It's an attempt to embody different incentives in the architecture itself.

```
ENGAGEMENT-OPTIMIZED APPS          GUARDIAN'S APPROACH
──────────────────────────         ─────────────────────
Maximize time on platform          Support self-regulation
Capture attention                  Develop attention
Create dependency                  Build autonomy
Extract data                       Data stays home
Same AI for all kids               Age-appropriate, values-aligned
Aligned with advertisers           Aligned with family
```

### The Tri-Track Architecture

The [architecture we're building](/posts/2026-01-12-guardian-architecture-research.html) has three tracks:

**Track A: SPR for Home** — Per-device identity without surveillance
**Track B: Mesh Network** — Family support that extends everywhere
**Track C: Family AI** — Local AI with YOUR values, not corporate values

The key insight: **the mesh unlocks portable family AI**. Without it, family AI only works at home. With it, your kid at school can ask for homework help from an AI that knows their age, respects your values, and doesn't extract their data.

### Design Principles from Research

Drawing from the research, Guardian's design principles:

**1. Support Autonomy, Don't Undermine It**

> "AI design should empower children to make autonomous decisions, promote critical thinking, and support self-directed learning." — [Springer research](https://link.springer.com/article/10.1007/s44436-025-00003-5)

Contracts are agreements, not impositions. Kids have voice in the process.

**2. Transparency Over Surveillance**

> "Monitoring and tracking students' online conversations and actions may limit their participation and make them feel unsafe to take ownership for their ideas." — [PMC research](https://pmc.ncbi.nlm.nih.gov/articles/PMC8455229/)

Kids see the same dashboard as parents. No secret monitoring.

**3. Eudaimonic Goals Over Hedonic Engagement**

> "The simultaneous pursuit of all three orientations — the full life — was associated with the highest degree of life satisfaction." — [Wellbeing research](https://www.internationaljournalofwellbeing.org/index.php/ijow/article/download/80/283/1183)

Guardian supports meaning, purpose, and growth — not just fun.

**4. Developmental Alignment**

> "Overly prescriptive algorithms may narrow children's learning experiences by guiding them along predetermined paths instead of fostering open-ended exploration." — [AI ethics research](https://link.springer.com/article/10.1007/s44436-025-00003-5)

Age-appropriate boundaries that evolve as children grow.

**5. Family Knowledge as Context**

AI that knows pet names, traditions, school context — not generic AI that treats every child the same.

---

## The Bigger Picture: Technology as Commons

### Beyond Individual Apps

The problem isn't just individual apps. It's the entire ecosystem of incentives.

[Platform cooperatives](https://platform.coop/blog/cooperatives-and-the-digital-commons-governance-sustainability-and-shared-infrastructure/) offer an alternative model:

```
EXTRACTIVE PLATFORM                COOPERATIVE MODEL
─────────────────                  ──────────────────
Owned by VCs                       Owned by users
Data as product                    Data as commons
Maximize extraction                Maximize member benefit
Misaligned incentives              Aligned incentives
```

Examples already exist:
- **CommonsCloud** (Spain) — Cooperative alternative to Google Drive
- **Gebied Online** (Netherlands) — Democratic Facebook alternative
- **Digital Commons Cooperative** — Technology for social change

### What Would Youth-Owned Technology Look Like?

Imagine if young people weren't just users, but co-owners and co-designers.

[Research on participatory design](https://dl.acm.org/doi/10.1145/3666094.3666108) shows that when children participate in design:

> "Common outcomes include agency, leadership, critical consciousness, confidence, academic engagement, social support, and interpersonal abilities."

The [KidsTeam at University of Washington](https://joanganzcooneycenter.org/2023/03/22/designing-with-kids/) demonstrates that children can be design partners, not just users. They can test, inform, and co-create.

What if the next generation of technology was built WITH young people, not just FOR them?

---

## The Window of Opportunity

### Haidt's Four Norms

At Davos, [Jonathan Haidt proposed](https://www.weforum.org/stories/2025/01/jonathan-haidt-digital-technology-social-media-childhood/) four new norms:

1. No smartphone until 14
2. No social media until 16
3. Phone-free schools
4. More independence in the real world

These are necessary but not sufficient. We also need to **build the alternative**.

### The Center for Humane Technology's Vision

The [Center for Humane Technology](https://www.humanetech.com/) advocates for technology that:

> "Prioritizes alignment with human values, including psychological well-being, democratic stability, and a robust shared information ecosystem, in opposition to extractive models that prioritize metrics like user attention and engagement."

Their "Time Well Spent" concept asks: what if technology was designed to help you spend time the way YOU want, not the way advertisers want?

### Guardian's Role

Guardian is one attempt at embodying these principles:

- **Local-first** — Data never leaves home
- **Transparent** — Everyone sees the same thing
- **Contract-based** — Agreements, not surveillance
- **Family AI** — Your values, portable everywhere
- **Open source** — Families can shape the tools

But more importantly, Guardian is trying to demonstrate that **alternative incentives produce alternative outcomes**.

When the incentive is family wellbeing instead of engagement metrics, you build different features. When data stays home instead of being extracted, you make different architectural choices. When kids have voice in the process, you get different relationships.

---

## The Choice Before Us

We're at an inflection point.

AI is being integrated into every product our children use. The question isn't whether AI will shape childhood — it's **whose AI, with what incentives**.

```
CORPORATE AI                       FAMILY-ALIGNED AI
───────────                        ─────────────────
Optimize for engagement            Optimize for flourishing
Same AI for everyone               Knows YOUR child
Aligned with advertisers           Aligned with YOU
Data feeds their models            Data stays home
Their values embedded              Your values embedded
```

The window is closing. In 18 months, "AI for children" will mean something. Either it will mean engagement-optimized corporate AI, or it will mean something genuinely different.

---

## What You Can Do

### For Parents

1. **Question the incentives** — Before any app, ask: how does this company make money? What behavior does that incentivize?
2. **Support alternatives** — Look for tools aligned with your values, even if less polished
3. **Talk about it** — Help your kids understand the attention economy

### For Builders

1. **Study the research** — Self-determination theory, METUX, developmentally aligned design
2. **Challenge engagement metrics** — What would you measure if you optimized for flourishing instead?
3. **Build local-first** — Architecture encodes values. Data that stays home can't be extracted.

### For Everyone

1. **Demand better** — The current system isn't inevitable
2. **Support the movement** — [The Anxious Generation movement](https://www.anxiousgeneration.com/), [Center for Humane Technology](https://www.humanetech.com/)
3. **Imagine alternatives** — The first step to building different is believing different is possible

---

## The Vision

A world where technology helps young people:

- Develop **autonomy** — the capacity to direct their own attention and make their own choices
- Build **competence** — real skills, not just achievement badges
- Experience **relatedness** — genuine connection, not likes and followers
- Find **meaning** — purpose larger than themselves
- **Flourish** — not just feel good, but become who they're capable of becoming

This isn't utopian. The research shows it's possible. The architecture exists. The question is whether we'll build it.

The incentives are wrong. Let's build tools with different incentives.

**The architecture is the ethics.**

---

*Let's GrOw!*

---

## Research Collection

This post draws from 50+ academic sources. Here's the full collection for those who want to go deeper.

### Foundational Psychology & Theory

- [Self-Determination Theory (Deci & Ryan)](https://selfdeterminationtheory.org/theory/) — Three innate needs: Autonomy, Competence, Relatedness
- [METUX Framework](https://pmc.ncbi.nlm.nih.gov/articles/PMC5985470/) — Technology can satisfy needs at interface level while harming life level
- [Hedonic vs Eudaimonic Wellbeing (Ryan & Deci)](https://selfdeterminationtheory.org/wp-content/uploads/2021/05/2001_RyanDeci_Happiness.pdf) — Pleasure vs meaning/purpose
- [Global Flourishing Study](https://hfh.fas.harvard.edu/global-flourishing-study) — Harvard's $43.4M, 200k participant, 22-country study
- [Ryff's Six Dimensions of Psychological Wellbeing](https://www.internationaljournalofwellbeing.org/index.php/ijow/article/download/80/283/1183)

### Attention Economy & Cognitive Autonomy

- [Georgetown Law: Attention Economy & Cognitive Autonomy](https://www.law.georgetown.edu/denny-center/blog/the-attention-economy/) — "Choice" as designed illusion
- [Youth Navigation of Autonomy (ages 15-19)](http://www.diva-portal.org/smash/get/diva2:1965040/FULLTEXT02.pdf) — Qualitative study on algorithmic environments
- [Digital Attention Heuristics](https://dl.acm.org/doi/10.1145/3725215) — 8 UI heuristics grounded in SDT
- [Harvard Crimson: Well-Being Paying for Attention Economy](https://www.thecrimson.com/article/2022/9/30/ling-attention-economy/)
- [Regulating the Attention Economy (2025)](https://journals.sagepub.com/doi/10.1177/00323292251375901)

### Children & AI Ethics

- [Developmentally Aligned Design (DAD)](https://link.springer.com/article/10.1007/s44436-025-00009-z) — 4 principles for child-centered AI
- [Oxford: AI Ethics Ignoring Children](https://www.ox.ac.uk/news/2024-03-20-ai-ethics-are-ignoring-children-say-oxford-researchers)
- [5Rights: Children & AI Design Code](https://5rightsfoundation.com/wp-content/uploads/2025/03/5rights_AI_CODE_DIGITAL.pdf)
- [Ethical AI in Early Childhood Education](https://link.springer.com/article/10.1007/s44436-025-00003-5)
- [PEARL-AI Framework for Child Health](https://pmc.ncbi.nlm.nih.gov/articles/PMC11893894/)
- [AI in K-12 Ethical Challenges](https://pmc.ncbi.nlm.nih.gov/articles/PMC8455229/)
- [AI Value Alignment (WEF)](https://www.weforum.org/stories/2024/10/ai-value-alignment-how-we-can-align-artificial-intelligence-with-human-values/)

### Youth Participatory Design

- [Youth Co-designing Digital Ecosystems (MIT)](https://wip.mitpress.mit.edu/pub/ak0y84jv)
- [Youth as Advisors in Algorithm Auditing](https://arxiv.org/abs/2504.07202)
- [Designing with Kids (Cooney Center)](https://joanganzcooneycenter.org/2023/03/22/designing-with-kids/) — Druin's design partner levels
- [Participatory Design with Activism (ACM PDC 2024)](https://dl.acm.org/doi/10.1145/3666094.3666108)
- [CO:RE Participatory Methods Toolkit](https://core-evidence.eu/posts/methods-toolkit-qualitative-participatory-methodologies)
- [Meaning of "Participation" in Co-Design](https://dl.acm.org/doi/abs/10.1002/pra2.432)

### Key Movements & Organizations

- [The Anxious Generation Movement](https://www.anxiousgeneration.com/) — Haidt's 4 norms
- [Jonathan Haidt at Davos 2025](https://www.weforum.org/stories/2025/01/jonathan-haidt-digital-technology-social-media-childhood/)
- [Center for Humane Technology](https://www.humanetech.com/)
- [Tristan Harris](https://www.tristanharris.com/) — Time Well Spent

### Platform Cooperatives & Digital Commons

- [Platform Cooperativism Consortium](https://platform.coop/) — 545 projects, 49 countries
- [Digital Commons Cooperative](https://digitalcommons.coop/about/)
- [Cooperatives & Digital Commons](https://platform.coop/blog/cooperatives-and-the-digital-commons-governance-sustainability-and-shared-infrastructure/)
- [OECD: Platform Cooperatives Report](https://www.oecd.org/content/dam/oecd/en/publications/reports/2023/09/empowering-communities-with-platform-cooperatives_63d716b6/c2ddfc9f-en.pdf)
- [Data Cooperatives for Digital Communities](https://www.mdpi.com/2673-6470/3/3/11)

### UX Design for Wellbeing

- [NN/g: SDT in UX Design](https://www.nngroup.com/articles/autonomy-relatedness-competence/)
- [Designing for Sustained Motivation (Oxford 2024)](https://academic.oup.com/iwc/advance-article/doi/10.1093/iwc/iwae040/7760010) — 50 design suggestions

### Youth Wellbeing Studies

- [Children's Digital Wellbeing 2024](https://www.internetmatters.org/hub/research/childrens-wellbeing-in-a-digital-world-index-report-2024/)
- [Eudaimonic Education-Entertainment (Pakistan)](https://www.researchsquare.com/article/rs-7755268/v1)
- [Self-Determination as PYD Construct](https://pmc.ncbi.nlm.nih.gov/articles/PMC3353314/)
- [Education for Flourishing in Adolescents](https://www.tandfonline.com/doi/full/10.1080/17439760.2025.2502480)
- [Hedonic/Eudaimonic Motives in Youth](https://www.researchgate.net/publication/350791505_Hedonic_and_eudaimonic_motives_to_pursue_well-being_in_three_samples_of_youth)

### Additional Academic Sources

- [Technology & Scaling Human Flourishing](https://link.springer.com/chapter/10.1007/978-3-031-93436-0_3)
- [AI Adoption Among Adolescents (UTAUT2)](https://pmc.ncbi.nlm.nih.gov/articles/PMC12451006/)
- [Self-Regulated Learning & SDT](https://pmc.ncbi.nlm.nih.gov/articles/PMC11979257/)
- [Unified Framework of Five Principles for AI (Harvard)](https://hdsr.mitpress.mit.edu/pub/l0jsh9d1)
